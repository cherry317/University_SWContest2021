# University_SWContest2021

_Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출하여 지자체의 의사결정에 지원해보기 위해 프로젝트를 수행함._

## 데이터 수집
<ul>
  <li> BeautifulSoup, Selenium 이용</li>
  <li> Naver(블로그/카페/지식인), Daum(블로그/카페) 포스팅 제목 및 본문 크롤링 - 총 9,173건</li>
  <li> 크롤링 코드는 별도의 repository를 생성하여 올릴 예정</li>
</ul>
  
## 데이터 전처리
<ul>
  <li> 홍보, 광고, 스팸 목적성 문서 제거</li>
  <li> 한글 외 문자 제거</li>  
  <li> Konlpy Komoran 이용한 형태소 분석 및 명사 추출</li>  
  <li> 불용어(무의미하거나 불필요한 단어) 제거</li>
</ul>

## LDA 토픽 모델링
### LDA 프로세스
<ol>
  <li><b> 토픽 개수 결정</b></li>
  - 전체 문서 데이터셋에서 추출할 토픽의 총 개수는 하이퍼파라미터로써 사용자가 직접 지정해야 한다.</br>
  - 일반적으로 토픽 모델링에서 토픽의 개수는 k로 표현하며 전체 문서의 개수는 M으로 표현한다.</br>
  - <b>토픽 수에 따른 성능 평가를 진행하여 최선의 토픽 개수를 선정한다.</b></br></br>
  
  <li><b> 단어의 토픽 할당</b></li>  
  - <b>LDA 알고리즘이 M개의 모든 문서 내 모든 단어를 k개의 토픽 중 하나로 임의로 할당하는 작업을 수행한다.</b></br> 
  - 이 작업을 마치면 모든 문서는 토픽을 갖게 되며 각 토픽은 단어 분포를 갖게 된다.</br>
  - 모든 단어를 각각 임의의 토픽에 할당하였기 때문에 토픽 내 단어 분포의 결과는 틀린 상태이다.</br></br>

  <li><b> 확률분포 기반 토픽 재할당</b></li>
  - 모든 단어에 대해 토픽을 재할당하기 위해, 모든 할당이 완료될 때까지 3-1과 3-2를 반복 수행한다.</br>
  - LDA는 문서 내 어떤 단어는 잘못된 토픽에 할당된 상태이지만, 다른 모든 단어들은 모두 올바른 토픽에 할당되어 있다고 가정한다.</br> 
  - 아래 3-1과 3-2와 같은 기준에 따라 토픽을 재할당한다. 아래의 2개의 문서를 예로 들어보겠다.</br></br>
  ![extopic](https://user-images.githubusercontent.com/103558593/210326163-2bd1ac45-4a55-4b1d-9130-62d59095d27d.png)
  
</ol>

### corpus 생성

### LDA 토픽 모델링

### 시각화

## 토픽별 주요 키워드 확인
<li> Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출한다.</li>

### 1. 워드클라우드 (빈도 기반 시각화)
<li> Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출한다.</li>

### 2. Word2Vec, TSNE (유사도 기반 시각화)
<li> Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출한다.</li>

## 긍부정 분석
<li> Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출한다.</li>

## 인사이트 도출
<li> Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출한다.</li>

## 마무리하며..
<li> Social-media 기반의 텍스트 마이닝을 통해 주요 인사이트를 도출한다.</li>
