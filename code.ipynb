{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51421306",
   "metadata": {},
   "source": [
    "# 라이브러리 import 및 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b073b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #경고 메시지 무시\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import pandas as pd \n",
    "import pickle \n",
    "import json\n",
    "import re #정규표현식 사용\n",
    "\n",
    "from tqdm import tqdm #진행표시바\n",
    "from konlpy.tag import Komoran #Kmoran 형태소 분석기 사용\n",
    "komoran=Komoran()\n",
    "\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline #브라우저 내부 시각화\n",
    "import matplotlib\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel #LDA 평가 지표\n",
    "\n",
    "import pyLDAvis.gensim_models #LDA 시각화\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549fc5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '' #파일 경로 지정\n",
    "font_path = path + '' #폰트 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ef22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_excel(path + 'rawdata.xlsx', engine=\"openpyxl\") #판다스의 기본 engine이 xlrd로 설정되어 있는 경우 오류 대비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7516246",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data.groupby(['ch','ch2']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa1c2b",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a23ab2f",
   "metadata": {},
   "source": [
    "### 홍보, 광고, 스팸 목적성 문서 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acae5620",
   "metadata": {},
   "outputs": [],
   "source": [
    "#제거할 문서의 기준이 되는 특정 단어 불러오기\n",
    "f = open(path + 'row_del.txt', 'r', encoding='UTF-8')\n",
    "remove = list(map(lambda x: x[:-1], f.readlines())) #읽어올때 개행문자 제거\n",
    "f.close()\n",
    "#remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 단어 포함 문서 제거  #홍보나 광고성 목적의 문서 제거\n",
    "indx = []\n",
    "for i in range(len(raw_data)):\n",
    "    for j in range(len(remove)):\n",
    "        if remove[j] in raw_data['document'][i] or remove[j] in raw_data['title'][i]:  #document나 title에 포함되는 문서 제거\n",
    "            indx.append(i)\n",
    "set_indx = list(dict.fromkeys(indx)) #리스트 순서 유지하면서 중복 인덱스 제거  #python 3.7버전부터 딕셔너리가 삽입 순서 보존"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = raw_data.drop(raw_data.index[set_indx])  #해당 인덱스 제거\n",
    "pre_data.reset_index(drop=True, inplace=True)  #데이터프레임 인덱스 리셋\n",
    "# pre_data  #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1234c",
   "metadata": {},
   "source": [
    "### 한글 외 문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b8393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문서 내용 한글만 남기고 제거\n",
    "pre_data['pre_doc'] = pre_data['document'].apply(lambda x: re.sub(\"[^가-힣]\", \" \", x))\n",
    "# pre_data  #출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab56e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문서 내용이 두글자 미만이나 공백인 경우 제거\n",
    "indx = []\n",
    "for i in range(len(pre_data)):\n",
    "    if (len(pre_data['pre_doc'][i]) < 2 or pre_data['pre_doc'][i].isspace() == True):\n",
    "        indx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10db6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = pre_data.drop(pre_data.index[indx])  #해당 인덱스 제거\n",
    "pre_data.reset_index(drop=True, inplace=True)  #데이터프레임 인덱스 리셋\n",
    "# pre_data  #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4eaa2",
   "metadata": {},
   "source": [
    "### 형태소 분석 및 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e02604",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_n=[]\n",
    "for doc in tqdm(pre_data['pre_doc']):\n",
    "    doc_n = list(term for term in komoran.nouns(doc) if len(term)>1) #형태소 분석_2글자 이상의 명사 추출  #for문 내 if문 구조\n",
    "    docs_n.append(doc_n) #이모티콘 등의 특수문자를 처리하는 경우, try except UnicodeDecodeError문 추가\n",
    "#docs_n   #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec2d5f",
   "metadata": {},
   "source": [
    "### 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 사전 읽어오기\n",
    "f = open(path + 'stopwords-ko.txt', 'r', encoding='UTF-8')\n",
    "stopwords = list(map(lambda x: x[:-1], f.readlines())) #읽어올때 개행문자 제거\n",
    "f.close()\n",
    "# stopwords   #출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1c5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추출한 명사에서 불용어 제거\n",
    "for doc_n in docs_n:\n",
    "    for word in stopwords:\n",
    "        while word in doc_n:\n",
    "            doc_n.remove(word)\n",
    "\n",
    "pre_data['doc_noun'] = docs_n  #데이터프레임에 삽입\n",
    "#pre_data   #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9b63a0",
   "metadata": {},
   "source": [
    "### 저장/읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66546a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle 파일 저장하는 함수\n",
    "def save(data, name):\n",
    "    with open(path+ f'{name}.pickle', 'wb') as f: \n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd523ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle 파일 불러오는 함수\n",
    "def load(name):\n",
    "    with open(path + f'{name}.pickle','rb') as fr:\n",
    "        data = pickle.load(fr)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5487a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(pre_data, 'pre_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f398d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_data = load('pre_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e5d26",
   "metadata": {},
   "source": [
    "# 토픽 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7b6e5",
   "metadata": {},
   "source": [
    "### corpus 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_dic = corpora.Dictionary(docs_n) #명사 리스트를 바탕으로 단어 빈도별 목록 생성 (토큰화)\n",
    "noun_dic.filter_extremes(no_below=3, no_above=0.9) # 빈도가 3 미만이거나 전체의 90% 이상인 단어 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0372f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [noun_dic.doc2bow(doc_n) for doc_n in docs_n] #토픽 모델링을 위한 DTM(문서단어행렬)을 생성 (벡터화)\n",
    "                                                        #doc2bow : 문서를 단어의 id와 빈도수로 수치화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55ae118",
   "metadata": {},
   "source": [
    "### 토픽 수에 따른 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토픽수에 따른 혼잡도와 일관성 분석 후, 최선의 토픽수 선정\n",
    "Lda = gensim.models.ldamodel.LdaModel  #토픽모델링 기법: 1.LDA(확률을 바탕으로 단어가 특정 주제에 존재할 확률과 문서에 특정 주제가 존재할 확률을 결합확률로 추정하여 토픽추출) / 2.LSA(분절된 단어들에 벡터값을 부여하고 차원축소를 하여 축소된 차원에서 근접한 단어들을 주제로 묶음)\n",
    "perplexity_score=[]\n",
    "coherence_score=[]\n",
    "\n",
    "for i in range(1,10): #토픽수가 1~ 9일때 혼잡도와 일관성을 측정\n",
    "    ldamodel=Lda(corpus, num_topics=i, id2word=noun_dic, passes=15, iterations=200, random_state=0)  #passes: 모델 학습시 전체 코퍼스에서 모델을 학습시키는 빈도  #iterations: 각 문서 반복 빈도\n",
    "    perplexity_score.append(ldamodel.log_perplexity(corpus)) \n",
    "    coherence_score.append(CoherenceModel(model=ldamodel, corpus=corpus, coherence='u_mass').get_coherence())\n",
    "    print(i, 'process complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efeaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,10),perplexity_score,'r',marker='^') #혼잡도 시각화\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.ylabel(\"perplexity score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aede129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,10),coherence_score,'b',marker='o') #일관성 시각화\n",
    "plt.xlabel(\"number of topics\")\n",
    "plt.ylabel(\"coherence score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f44d6",
   "metadata": {},
   "source": [
    "### LDA 토픽 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fad806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#지정 토픽수로 토픽 모델링 진행\n",
    "lda_model = Lda(corpus, num_topics=4, id2word=noun_dic, passes=15, iterations=200, random_state=0)\n",
    "\n",
    "#토픽별 5 단어씩 출력\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133274a",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d243beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, noun_dic)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, path + 'ldamodel.html') #토픽모델링 결과를 html로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ba6b7f",
   "metadata": {},
   "source": [
    "### 데이터프레임에 토픽 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for i in range(len(corpus)):\n",
    "    prop_sort=[]\n",
    "    topic_sort=[]\n",
    "    for topic , prop in lda_model.get_document_topics(corpus)[i]:\n",
    "        prop_sort.append(prop)\n",
    "        topic_sort.append(topic)\n",
    "    topics.append(topic_sort[prop_sort.index(max(prop_sort))]) #각 문서를 가장 큰 확률을 가진 토픽에 배정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969b7162",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = pre_data[['pre_doc','doc_noun']]\n",
    "total_docs['topic'] = topics\n",
    "total_docs['topic'] = total_docs['topic'].apply(lambda x: x+1) #topic이 0부터 시작하는 것을 1부터 시작으로 변경\n",
    "# total_docs   #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4ce38",
   "metadata": {},
   "source": [
    "### 저장/읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(total_docs, 'topic_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205c0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = load('topic_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab50ec0",
   "metadata": {},
   "source": [
    "# 토픽별 주요 키워드 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da4a50a",
   "metadata": {},
   "source": [
    "## 1. 워드클라우드 (빈도 기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aad8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#상위 빈도 단어 50개를 추출하는 함수\n",
    "def noun_list(cate):\n",
    "    if cate == 'total':\n",
    "        df = total_docs\n",
    "    else:\n",
    "        df = total_docs[total_docs['topic']==cate]\n",
    "        \n",
    "    noun_list = list(itertools.chain(*list(df['doc_noun'])))\n",
    "    count = Counter(noun_list)\n",
    "    print(len(count)) #단어 종류 수\n",
    "    fift = dict(count.most_common(50))\n",
    "    return fift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121610fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#워드클라우드로 시각화하는 함수\n",
    "def fwordcloud(cate):  #category: 'total', 1, 2, 3, 4\n",
    "    fift = noun_list(cate)\n",
    "    matplotlib.rc('font', family='Malgun Gothic')\n",
    "    set_matplotlib_formats('retina')  #한글 선명하게\n",
    "    wordcloud = WordCloud(font_path=font_path, background_color='white',colormap=\"Accent_r\", width=1500, height=1000).generate_from_frequencies(fift) \n",
    "\n",
    "    if cate == 'total':\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(path + 'total.png') #이미지 저장\n",
    "    else:\n",
    "        plt.imshow(wordcloud)\n",
    "        plt.axis('off')\n",
    "        plt.savefig(path + f'topic{cate}.png') #이미지 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6954da",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f1e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwordcloud('total') #전체 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec77755",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwordcloud(1) #토픽1 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwordcloud(2) #토픽2 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwordcloud(3) #토픽3 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca45b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwordcloud(4) #토픽4 단어 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38660d3",
   "metadata": {},
   "source": [
    "## 2. Word2Vec, TSNE (유사도 기반)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94691f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w2v을 이용하여 단어를 유사도로 벡터화하는 함수\n",
    "def w2v(topic):\n",
    "    df = total_docs[total_docs['topic']==topic]\n",
    "    model = Word2Vec(sentences = df['doc_noun'], size=50, window = 15, min_count=100, workers=4, iter=100, sg=1)\n",
    "    word_vectors = model.wv.vectors # 어휘의 feature vector\n",
    "    topic_w2v = (model, word_vectors)\n",
    "    return topic_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342fb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic1_w2v = w2v(1)\n",
    "topic2_w2v = w2v(2)\n",
    "topic3_w2v = w2v(3)\n",
    "topic4_w2v = w2v(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d409dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne를 이용하여 2차원으로 시각화 (단어간 유사할수록 밀집되어 있음)\n",
    "def tsne(w2v):\n",
    "    vocab = list(w2v[0].wv.vocab)\n",
    "    X = w2v[0][vocab]\n",
    "    tsne = TSNE(n_components=2, random_state = 3, learning_rate = 500)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "    df_plot = pd.DataFrame(X_tsne, index=vocab, columns=[\"x\", \"y\"])\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(10, 10)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    ax.scatter(df_plot['x'], df_plot['y'])\n",
    "    \n",
    "    for word, pos in df_plot.iterrows():\n",
    "        ax.annotate(word, pos)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88971644",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a62663",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(topic1_w2v)  #토픽1 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ea62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(topic2_w2v) #토픽2 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64d02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(topic3_w2v) #토픽3 단어 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed380821",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne(topic4_w2v) #토픽4 단어 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ace6efe",
   "metadata": {},
   "source": [
    "# 긍부정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc2140",
   "metadata": {},
   "source": [
    "### 각 문서별 긍부정 점수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0baf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(name):\n",
    "    with open(path + f'{name}.json', encoding='UTF-8') as fr:\n",
    "        data = json.load(fr)\n",
    "        json_data = pd.DataFrame(data)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd35ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = load_json('Sentiword_info')\n",
    "# s   #출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377f571",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_word = []  #감성사전 단어와 일치하는 단어\n",
    "values = []  #문서에 부여된 값들\n",
    "score = []   #문서 평균 점수\n",
    "\n",
    "def average(list): #각 문서별 평균 긍부정 점수를 계산하는 함수\n",
    "    return sum(list)/len(list)\n",
    "\n",
    "for word in tqdm(total_docs['pre_doc']):\n",
    "    temp_s_word=[]\n",
    "    temp_value=[]\n",
    "    for i in range(len(s)):\n",
    "        if s.iloc[i]['word'] in word and len(s.iloc[i]['word']) > 1:  #감성사전 단어가 2글자 이상이며 문서 내 존재하는 경우, 점수 계산\n",
    "            temp_s_word.append(s.iloc[i]['word'])\n",
    "            temp_value.append(int(s.iloc[i]['polarity']))\n",
    "    s_word.append(temp_s_word)\n",
    "    values.append(temp_value)\n",
    "    try:\n",
    "        score.append(average(temp_value))\n",
    "    except ZeroDivisionError:  #평균 점수를 계산할 값이 없는 경우  #0을 나누려할 때 나타남\n",
    "        score.append(int(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs=total_docs.assign(sentiword=s_word, values=values, score=score)  #데이터프레임에 삽입\n",
    "# total_docs   #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c7677",
   "metadata": {},
   "source": [
    "### 저장/읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdebf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "save(total_docs, 'senti_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = load('senti_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3426634d",
   "metadata": {},
   "source": [
    "### 데이터프레임에 긍부정 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbdb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti = []\n",
    "for i in range(len(total_docs)):\n",
    "    if total_docs['score'][i] > 0:    #평균 점수>0 :긍정\n",
    "        senti.append('긍정')\n",
    "    elif total_docs['score'][i] < 0:  #평균 점수<0 :부정\n",
    "        senti.append('부정')\n",
    "    else:                             #평균 점수=0 :중립\n",
    "        senti.append('중립') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bd0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs['senti'] = senti\n",
    "# total_docs   #출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa485d7",
   "metadata": {},
   "source": [
    "### 각 토픽별 긍부정 비율 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5e274f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#각 토픽별 긍부정 문서 비율을 계산하는 함수\n",
    "def senti_cnt(topic):\n",
    "    df = total_docs[total_docs['topic']==topic]\n",
    "    pos = len(df[df['senti']=='긍정'])\n",
    "    neu = len(df[df['senti']=='중립'])\n",
    "    neg = len(df[df['senti']=='부정'])\n",
    "    return [pos, neu, neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea5d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# senti_cnt(1)  #출력  #토픽넘버에 해당하는 긍부정 문서 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9de4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_bar = pd.DataFrame([senti_cnt(1),senti_cnt(2),senti_cnt(3),senti_cnt(4)],\n",
    "                  index=['topic1','topic2','topic3','topic4'],\n",
    "                  columns=['긍정','중립','부정'])\n",
    "# senti_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85a10ca",
   "metadata": {},
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4adff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#막대 그래프 시각화\n",
    "senti_plot = senti_bar.plot(kind='bar',\n",
    "                            color=['dimgray', 'darkgray','lightgray'],\n",
    "                           figsize=(11,7), rot=0, width = 0.85)\n",
    "\n",
    "le=[]\n",
    "he=[]\n",
    "for p in senti_plot.patches:\n",
    "    left, bottom, width, height = p.get_bbox().bounds \n",
    "    le.append(left)   #막대 그래프 위치 x값\n",
    "    he.append(height) #막대 그래프 위치 y값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ef0406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래프에 글자 추가\n",
    "senti_plot = senti_bar.plot(kind='bar',\n",
    "                            color=['dimgray', 'darkgray','lightgray'],\n",
    "                           figsize=(11,7), rot=0, width = 0.85)\n",
    "\n",
    "# topic1 긍부정 비율\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(1)[0]/sum(senti_cnt(1)) ), (le[0]+0.3/2, he[0]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(1)[1]/sum(senti_cnt(1)) ), (le[4]+0.3/2, he[4]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(1)[2]/sum(senti_cnt(1)) ), (le[8]+0.3/2, he[8]*1.02), ha='center',fontsize=14)\n",
    "\n",
    "# topic2 긍부정 비율\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(2)[0]/sum(senti_cnt(2)) ), (le[1]+0.3/2, he[1]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(2)[1]/sum(senti_cnt(2)) ), (le[5]+0.3/2, he[5]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(2)[2]/sum(senti_cnt(2)) ), (le[9]+0.3/2, he[9]*1.02), ha='center',fontsize=14)\n",
    "\n",
    "# topic3 긍부정 비율\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(3)[0]/sum(senti_cnt(3)) ), (le[2]+0.3/2, he[2]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(3)[1]/sum(senti_cnt(3)) ), (le[6]+0.3/2, he[6]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(3)[2]/sum(senti_cnt(3)) ), (le[10]+0.3/2, he[10]*1.02), ha='center',fontsize=14)\n",
    "\n",
    "# topic4 긍부정 비율\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(4)[0]/sum(senti_cnt(4)) ), (le[3]+0.3/2, he[3]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(4)[1]/sum(senti_cnt(4)) ), (le[7]+0.3/2, he[7]*1.02), ha='center',fontsize=14)\n",
    "senti_plot.annotate(\"%.2f%%\"%( senti_cnt(4)[2]/sum(senti_cnt(4)) ), (le[11]+0.3/2, he[11]*1.02), ha='center',fontsize=14)\n",
    "\n",
    "senti_plot.legend(fontsize=13,loc=2)  # label 글자 크기, 위치 조정"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
